{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T13:31:17.683218Z",
     "iopub.status.busy": "2020-07-29T13:31:17.683218Z",
     "iopub.status.idle": "2020-07-29T13:31:17.689213Z",
     "shell.execute_reply": "2020-07-29T13:31:17.688221Z",
     "shell.execute_reply.started": "2020-07-29T13:31:17.683218Z"
    }
   },
   "outputs": [],
   "source": [
    "MOVIES = []\n",
    "BASE_DOMAIN = 'https://www.dytt8.net'\n",
    "HEADERS = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36',\n",
    "}\n",
    "def get_detail_urls(url, headers=HEADERS):\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    # print(response.text)  有乱码\n",
    "    # 可以从网页源代码中查看编码格式\n",
    "    # F12 在console输入document.charset 查看编码方式\n",
    "    text = response.content.decode('gbk', errors='ignore')\n",
    "    html = etree.HTML(text)\n",
    "    detail_urls = html.xpath(\"//table[@class='tbspan']//a/@href\")\n",
    "    detail_urls = map(lambda url: BASE_DOMAIN + url, detail_urls)\n",
    "    return detail_urls\n",
    "            \n",
    "def parse_detail_page(url):\n",
    "    movie = {}\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    text = response.content.decode('gbk')\n",
    "    html = etree.HTML(text)\n",
    "    title = html.xpath(\"//div[@class='title_all']//font[@color='#07519a']/text()\")[0]\n",
    "    movie['title'] = title\n",
    "    \n",
    "    zoomE = html.xpath(\"//div[@id='Zoom']\")[0]\n",
    "    imgs = zoomE.xpath(\".//img/@src\")\n",
    "    cover = imgs[0]\n",
    "    #screenshot = imgs[1]\n",
    "    movie['cover'] = cover\n",
    "    #movie['screenshot'] = screenshot\n",
    "    \n",
    "    def parse_info(info,rule):\n",
    "        return info.replace(rule,'').strip()\n",
    "    infos = zoomE.xpath(\".//text()\")\n",
    "    for index, info in enumerate(infos):\n",
    "        if info.startswith('◎年　　代'):\n",
    "            info = parse_info(info, '◎年　　代')\n",
    "            movie['year'] = info\n",
    "        elif info.startswith('◎产　　地'):\n",
    "            info = parse_info(info, '◎产　　地')\n",
    "            movie['country'] = info\n",
    "        elif info.startswith('◎类　　别'):\n",
    "            info = parse_info(info, '◎类　　别')\n",
    "            movie['catergory'] = info\n",
    "        elif info.startswith('◎豆瓣评分'):\n",
    "            info = parse_info(info, '◎豆瓣评分')\n",
    "            movie['score'] = info\n",
    "        elif info.startswith('◎片　　长'):\n",
    "            info = parse_info(info, '◎片　　长')\n",
    "            movie['duration'] = info\n",
    "        elif info.startswith('◎导　　演'):\n",
    "            info = parse_info(info, '◎导　　演')\n",
    "            movie['director'] = info\n",
    "        elif info.startswith('◎主　　演'):\n",
    "            info = parse_info(info, '◎主　　演')\n",
    "            actors = [info]\n",
    "            for i in range(index+1,len(infos)):\n",
    "                actor = infos[i].strip()\n",
    "                if actor.startswith('◎'):\n",
    "                    break\n",
    "                actors.append(actor)\n",
    "            movie['actors'] = actors\n",
    "        elif info.startswith('◎简　　介'):\n",
    "            info = parse_info(info, '◎简　　介')\n",
    "            movie['introduce'] = infos[index+1]\n",
    "    download_url = html.xpath(\"//td[@bgcolor='#fdfddf']/a/@href\")[0]\n",
    "    movie['download_url'] = download_url\n",
    "    return movie\n",
    "     \n",
    "def spider():\n",
    "    base_url = 'https://www.dytt8.net/html/gndy/dyzz/list_23_{}.html'\n",
    "    global movies\n",
    "    movies = []\n",
    "    # 遍历所有页\n",
    "    for x in range(1,2):\n",
    "        url = base_url.format(x)\n",
    "        detail_urls = get_detail_urls(url)\n",
    "        # 遍历每页的电影详情url\n",
    "        for detail_url in detail_urls:\n",
    "            movie = parse_detail_page(detail_url)\n",
    "            movies.append(movie)\n",
    "            print(movies,'\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
